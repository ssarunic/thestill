# LLM Provider Configuration
# Choose between 'openai', 'ollama', 'gemini', or 'anthropic'
LLM_PROVIDER=openai

# OpenAI API Configuration (required if LLM_PROVIDER=openai)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-5.1
# Recommended models:
# - gpt-5.1 (default, adaptive reasoning - Nov 2025)
# - gpt-5.1-codex (optimized for coding tasks)
# - gpt-5.1-codex-max (1M context, multi-window agentic tasks)
# - gpt-4.1 (previous flagship, good balance)
# - gpt-4.1-mini (fast and cost-effective)
# - o3 (advanced reasoning model)
# - o4-mini (efficient reasoning)

# Ollama Configuration (required if LLM_PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gemma3:4b

# Google Gemini Configuration (required if LLM_PROVIDER=gemini)
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-3-pro-preview
# Recommended models:
# - gemini-3-pro-preview (latest flagship, 1M context - Dec 2025)
# - gemini-3-flash-preview (fast, cost-effective - Dec 2025)
# - gemini-2.5-pro (stable, 1M context with thinking)
# - gemini-2.5-flash (fast, cost-effective)

GEMINI_THINKING_LEVEL=
# Optional: Thinking level for Gemini 3 models (controls reasoning depth)
# Pro models: low, high (default)
# Flash models: minimal, low, medium, high (default)
# Leave empty for API default (high). Set to "low" for transcript cleaning to reduce token usage.
# Note: Gemini 1.5 series retired April 2025

# Anthropic Claude Configuration (required if LLM_PROVIDER=anthropic)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-sonnet-4-5-20250929
# Recommended models:
# - claude-opus-4-5-20251101 (best for coding/agents - Nov 2025, 64K output)
# - claude-sonnet-4-5-20250929 (default, balanced performance, 64K output)
# - claude-haiku-4-5-20251015 (fast and cost-effective)
# Legacy: claude-3-5-sonnet-20241022 (older but still available)

# Storage Configuration
STORAGE_PATH=./data
DATABASE_PATH=./data/podcasts.db  # SQLite database path (default: STORAGE_PATH/podcasts.db)


# Processing Configuration
MAX_WORKERS=3
CHUNK_DURATION_MINUTES=30

# Podcast Episode Limits
MAX_EPISODES_PER_PODCAST=
# Optional: Limit the maximum number of episodes tracked per podcast during discovery
# If set, only the N most recent episodes will be discovered and tracked per podcast
# Leave empty or comment out to track all episodes (default behavior)
# Useful for podcasts with hundreds of episodes to keep feeds.json manageable
# Example: MAX_EPISODES_PER_PODCAST=50

# Transcription Provider Configuration
TRANSCRIPTION_PROVIDER=whisper
# Options: whisper, google, elevenlabs
# whisper: Local OpenAI Whisper transcription (CPU/GPU)
# google: Google Cloud Speech-to-Text API (cloud-based)
# elevenlabs: ElevenLabs Speech-to-Text API (cloud-based)

# Whisper Configuration (used when TRANSCRIPTION_PROVIDER=whisper)
TRANSCRIPTION_MODEL=whisper
# Options: whisper, parakeet

WHISPER_MODEL=base
# Options: tiny, base, small, medium, large

WHISPER_DEVICE=auto
# Options: auto, cpu, cuda
# auto: Automatically select best device
# cpu: Force CPU usage
# cuda: Use NVIDIA GPU if available

# Google Cloud Speech-to-Text Configuration (required if TRANSCRIPTION_PROVIDER=google)
GOOGLE_APP_CREDENTIALS=
# Path to Google Cloud service account JSON key file
# Example: /path/to/service-account-key.json
# Get credentials: https://console.cloud.google.com/apis/credentials

GOOGLE_CLOUD_PROJECT_ID=
# Your Google Cloud project ID
# Find at: https://console.cloud.google.com/

GOOGLE_STORAGE_BUCKET=
# Optional: GCS bucket name for large files (>10MB)
# If not specified, a bucket will be auto-created: thestill-transcription-{project_id}
# Small files (<10MB) use synchronous API without GCS

# ElevenLabs Speech-to-Text Configuration (required if TRANSCRIPTION_PROVIDER=elevenlabs)
ELEVENLABS_API_KEY=
# Your ElevenLabs API key
# Get from: https://elevenlabs.io/app/settings/api-keys

ELEVENLABS_MODEL=scribe_v1
# Options: scribe_v1, scribe_v1_experimental
# scribe_v1: Stable, high-accuracy transcription
# scribe_v1_experimental: Latest features (may be less stable)

# Speaker Diarization Configuration
ENABLE_DIARIZATION=false
# Set to 'true' to enable speaker identification in transcripts
# For whisper: Uses pyannote.audio (requires HUGGINGFACE_TOKEN)
# For google: Built-in speaker diarization (no additional setup)
# For elevenlabs: Built-in speaker diarization (up to 32 speakers)

DIARIZATION_MODEL=pyannote/speaker-diarization-3.1
# Whisper only: pyannote speaker diarization model from HuggingFace

HUGGINGFACE_TOKEN=
# Whisper only: Required for pyannote models
# Get token from https://huggingface.co/settings/tokens
# You must also accept the model license at https://huggingface.co/pyannote/speaker-diarization-3.1

MIN_SPEAKERS=
# Minimum number of speakers (leave empty for provider's auto-detection defaults)
# Used by both whisper and google providers
# Only set explicitly if you know the podcast structure (e.g., MIN_SPEAKERS=1 for solo show)

MAX_SPEAKERS=
# Maximum number of speakers (leave empty for provider's auto-detection defaults)
# Used by both whisper and google providers
# Only set explicitly if you know the podcast structure (e.g., MAX_SPEAKERS=8 for panel discussions)

# Transcript Cleaning Configuration (Optional)
# Enable LLM-based transcript cleaning to fix errors, remove fillers, improve readability
ENABLE_TRANSCRIPT_CLEANING=false
# Set to 'true' to enable cleaning after transcription

CLEANING_PROVIDER=ollama
# Provider for transcript cleaning: 'openai', 'ollama', 'gemini', or 'anthropic'
# Recommended: ollama with small models (gemma3:1b, gemma3:4b), gemini-2.5-flash, or claude-haiku-4-5

CLEANING_MODEL=gemma3:4b
# Model for cleaning. Small models recommended:
# - gemma3:270m (fastest, lowest quality)
# - gemma3:1b (fast, good for simple cleaning)
# - gemma3:4b (balanced, recommended)
# - gpt-4o-mini (OpenAI, high quality but costs money)

CLEANING_CHUNK_SIZE=20000
# Max tokens per chunk (default: 20000)
# Adjust based on model's context window

CLEANING_OVERLAP_PCT=0.15
# Overlap percentage between chunks (default: 0.15 = 15%)
# Higher overlap = better context but more processing

CLEANING_EXTRACT_ENTITIES=true
# Extract entities (names, companies, acronyms) for consistency
# Set to 'false' to skip entity extraction and speed up processing

# Cleanup Configuration
CLEANUP_DAYS=30
# Number of days after which to delete old audio files

# Debug/Testing Configuration
# DEBUG_CLIP_DURATION=300
# Clip audio to N seconds for faster testing (e.g., 300 = 5 minutes)
# Leave commented out or empty for full-length processing
