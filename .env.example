# LLM Provider Configuration
# Choose between 'openai' or 'ollama'
LLM_PROVIDER=openai

# OpenAI API Configuration (required if LLM_PROVIDER=openai)
OPENAI_API_KEY=your_openai_api_key_here
LLM_MODEL=gpt-4o

# Ollama Configuration (required if LLM_PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gemma3:4b

# Storage Configuration
STORAGE_PATH=./data
AUDIO_PATH=./data/audio
TRANSCRIPTS_PATH=./data/transcripts
SUMMARIES_PATH=./data/summaries

# Processing Configuration
MAX_WORKERS=3
CHUNK_DURATION_MINUTES=30

# Transcription Configuration
TRANSCRIPTION_MODEL=whisper
# Options: whisper, parakeet

WHISPER_MODEL=base
# Options: tiny, base, small, medium, large

WHISPER_DEVICE=auto
# Options: auto, cpu, cuda
# auto: Automatically select best device
# cpu: Force CPU usage
# cuda: Use NVIDIA GPU if available

# Speaker Diarization Configuration
ENABLE_DIARIZATION=false
# Set to 'true' to enable speaker identification in transcripts

DIARIZATION_MODEL=pyannote/speaker-diarization-3.1
# pyannote speaker diarization model from HuggingFace

HUGGINGFACE_TOKEN=
# Required for pyannote models - get token from https://huggingface.co/settings/tokens
# You must also accept the model license at https://huggingface.co/pyannote/speaker-diarization-3.1

MIN_SPEAKERS=
# Minimum number of speakers (leave empty for auto-detection)

MAX_SPEAKERS=
# Maximum number of speakers (leave empty for auto-detection)

# Transcript Cleaning Configuration (Optional)
# Enable LLM-based transcript cleaning to fix errors, remove fillers, improve readability
ENABLE_TRANSCRIPT_CLEANING=false
# Set to 'true' to enable cleaning after transcription

CLEANING_PROVIDER=ollama
# Provider for transcript cleaning: 'openai' or 'ollama'
# Recommended: ollama with small models (gemma3:1b, gemma3:4b)

CLEANING_MODEL=gemma3:4b
# Model for cleaning. Small models recommended:
# - gemma3:270m (fastest, lowest quality)
# - gemma3:1b (fast, good for simple cleaning)
# - gemma3:4b (balanced, recommended)
# - gpt-4o-mini (OpenAI, high quality but costs money)

CLEANING_CHUNK_SIZE=20000
# Max tokens per chunk (default: 20000)
# Adjust based on model's context window

CLEANING_OVERLAP_PCT=0.15
# Overlap percentage between chunks (default: 0.15 = 15%)
# Higher overlap = better context but more processing

CLEANING_EXTRACT_ENTITIES=true
# Extract entities (names, companies, acronyms) for consistency
# Set to 'false' to skip entity extraction and speed up processing

# Cleanup Configuration
CLEANUP_DAYS=30
# Number of days after which to delete old audio files

# Debug/Testing Configuration
# DEBUG_CLIP_DURATION=300
# Clip audio to N seconds for faster testing (e.g., 300 = 5 minutes)
# Leave commented out or empty for full-length processing