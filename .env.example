# LLM Provider Configuration
# Choose between 'openai', 'ollama', 'gemini', or 'anthropic'
LLM_PROVIDER=openai

# OpenAI API Configuration (required if LLM_PROVIDER=openai)
OPENAI_API_KEY=your_openai_api_key_here
LLM_MODEL=gpt-4o

# Ollama Configuration (required if LLM_PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gemma3:4b

# Google Gemini Configuration (required if LLM_PROVIDER=gemini)
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.0-flash-exp
# Recommended models: gemini-2.0-flash-exp, gemini-1.5-flash, gemini-1.5-pro

# Anthropic Claude Configuration (required if LLM_PROVIDER=anthropic)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
# Recommended models: claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022, claude-3-opus-20240229

# Storage Configuration
STORAGE_PATH=./data
AUDIO_PATH=./data/audio
TRANSCRIPTS_PATH=./data/transcripts
SUMMARIES_PATH=./data/summaries

# Processing Configuration
MAX_WORKERS=3
CHUNK_DURATION_MINUTES=30

# Podcast Episode Limits
MAX_EPISODES_PER_PODCAST=
# Optional: Limit the maximum number of episodes tracked per podcast during discovery
# If set, only the N most recent episodes will be discovered and tracked per podcast
# Leave empty or comment out to track all episodes (default behavior)
# Useful for podcasts with hundreds of episodes to keep feeds.json manageable
# Example: MAX_EPISODES_PER_PODCAST=50

# Transcription Provider Configuration
TRANSCRIPTION_PROVIDER=whisper
# Options: whisper, google
# whisper: Local OpenAI Whisper transcription (CPU/GPU)
# google: Google Cloud Speech-to-Text API (cloud-based)

# Whisper Configuration (used when TRANSCRIPTION_PROVIDER=whisper)
TRANSCRIPTION_MODEL=whisper
# Options: whisper, parakeet

WHISPER_MODEL=base
# Options: tiny, base, small, medium, large

WHISPER_DEVICE=auto
# Options: auto, cpu, cuda
# auto: Automatically select best device
# cpu: Force CPU usage
# cuda: Use NVIDIA GPU if available

# Google Cloud Speech-to-Text Configuration (required if TRANSCRIPTION_PROVIDER=google)
GOOGLE_APP_CREDENTIALS=
# Path to Google Cloud service account JSON key file
# Example: /path/to/service-account-key.json
# Get credentials: https://console.cloud.google.com/apis/credentials

GOOGLE_CLOUD_PROJECT_ID=
# Your Google Cloud project ID
# Find at: https://console.cloud.google.com/

GOOGLE_STORAGE_BUCKET=
# Optional: GCS bucket name for large files (>10MB)
# If not specified, a bucket will be auto-created: thestill-transcription-{project_id}
# Small files (<10MB) use synchronous API without GCS

# Speaker Diarization Configuration
ENABLE_DIARIZATION=false
# Set to 'true' to enable speaker identification in transcripts
# For whisper: Uses pyannote.audio (requires HUGGINGFACE_TOKEN)
# For google: Built-in speaker diarization (no additional setup)

DIARIZATION_MODEL=pyannote/speaker-diarization-3.1
# Whisper only: pyannote speaker diarization model from HuggingFace

HUGGINGFACE_TOKEN=
# Whisper only: Required for pyannote models
# Get token from https://huggingface.co/settings/tokens
# You must also accept the model license at https://huggingface.co/pyannote/speaker-diarization-3.1

MIN_SPEAKERS=
# Minimum number of speakers (leave empty for provider's auto-detection defaults)
# Used by both whisper and google providers
# Only set explicitly if you know the podcast structure (e.g., MIN_SPEAKERS=1 for solo show)

MAX_SPEAKERS=
# Maximum number of speakers (leave empty for provider's auto-detection defaults)
# Used by both whisper and google providers
# Only set explicitly if you know the podcast structure (e.g., MAX_SPEAKERS=8 for panel discussions)

# Transcript Cleaning Configuration (Optional)
# Enable LLM-based transcript cleaning to fix errors, remove fillers, improve readability
ENABLE_TRANSCRIPT_CLEANING=false
# Set to 'true' to enable cleaning after transcription

CLEANING_PROVIDER=ollama
# Provider for transcript cleaning: 'openai', 'ollama', 'gemini', or 'anthropic'
# Recommended: ollama with small models (gemma3:1b, gemma3:4b), gemini-1.5-flash, or claude-3-5-haiku

CLEANING_MODEL=gemma3:4b
# Model for cleaning. Small models recommended:
# - gemma3:270m (fastest, lowest quality)
# - gemma3:1b (fast, good for simple cleaning)
# - gemma3:4b (balanced, recommended)
# - gpt-4o-mini (OpenAI, high quality but costs money)

CLEANING_CHUNK_SIZE=20000
# Max tokens per chunk (default: 20000)
# Adjust based on model's context window

CLEANING_OVERLAP_PCT=0.15
# Overlap percentage between chunks (default: 0.15 = 15%)
# Higher overlap = better context but more processing

CLEANING_EXTRACT_ENTITIES=true
# Extract entities (names, companies, acronyms) for consistency
# Set to 'false' to skip entity extraction and speed up processing

# Cleanup Configuration
CLEANUP_DAYS=30
# Number of days after which to delete old audio files

# Debug/Testing Configuration
# DEBUG_CLIP_DURATION=300
# Clip audio to N seconds for faster testing (e.g., 300 = 5 minutes)
# Leave commented out or empty for full-length processing